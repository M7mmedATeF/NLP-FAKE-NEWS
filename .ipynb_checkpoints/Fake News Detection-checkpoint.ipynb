{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48e9ec9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>Alabama Sen. Sessions Backs Trump’s Immigratio...</td>\n",
       "      <td>Donald Trump received a key endorsement for hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654</th>\n",
       "      <td>As of 6:00 AM NOVEMBER 6th, Trump is leading i...</td>\n",
       "      <td>Nina November 6, 2016 @ 2:39 pm \\nPolish gover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>Time: Investigating Hillary is an Attack on Al...</td>\n",
       "      <td>Time: Investigating Hillary is an Attack on Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>Women Should Vote With Their Husbands</td>\n",
       "      <td>Taki's Magazine October 28, 2016 \\nThis electi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4371</th>\n",
       "      <td>Pakistan police detain dozens of Imran Khan's ...</td>\n",
       "      <td>Pakistan Pakistan's cricketer turned politicia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>The inane spectacle of the GOP debate: Cruz th...</td>\n",
       "      <td>What happened was less a debate among contende...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>Clinton, FBIGate and the true depth of the Oba...</td>\n",
       "      <td>Clinton, FBIGate and the true depth of the Oba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>Fearing Election Day Trouble, Some US Schools ...</td>\n",
       "      <td>Fearing Election Day Trouble, Some US Schools ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>Obama gets away with some whoppers on guns at ...</td>\n",
       "      <td>President Obama’s appearance at a town hall me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>CETA: Canada Has Challenged The EU’s Chemical ...</td>\n",
       "      <td>A man protests against international trade agr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5068 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "1142  Alabama Sen. Sessions Backs Trump’s Immigratio...   \n",
       "2654  As of 6:00 AM NOVEMBER 6th, Trump is leading i...   \n",
       "5395  Time: Investigating Hillary is an Attack on Al...   \n",
       "1170              Women Should Vote With Their Husbands   \n",
       "4371  Pakistan police detain dozens of Imran Khan's ...   \n",
       "...                                                 ...   \n",
       "3772  The inane spectacle of the GOP debate: Cruz th...   \n",
       "5191  Clinton, FBIGate and the true depth of the Oba...   \n",
       "5226  Fearing Election Day Trouble, Some US Schools ...   \n",
       "5390  Obama gets away with some whoppers on guns at ...   \n",
       "860   CETA: Canada Has Challenged The EU’s Chemical ...   \n",
       "\n",
       "                                                   text  \n",
       "1142  Donald Trump received a key endorsement for hi...  \n",
       "2654  Nina November 6, 2016 @ 2:39 pm \\nPolish gover...  \n",
       "5395  Time: Investigating Hillary is an Attack on Al...  \n",
       "1170  Taki's Magazine October 28, 2016 \\nThis electi...  \n",
       "4371  Pakistan Pakistan's cricketer turned politicia...  \n",
       "...                                                 ...  \n",
       "3772  What happened was less a debate among contende...  \n",
       "5191  Clinton, FBIGate and the true depth of the Oba...  \n",
       "5226  Fearing Election Day Trouble, Some US Schools ...  \n",
       "5390  President Obama’s appearance at a town hall me...  \n",
       "860   A man protests against international trade agr...  \n",
       "\n",
       "[5068 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"news.csv\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df[['title', 'text']], df['label'], test_size=0.2, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "198e49d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "addToSW = set(['\\'',':',';','\\''])\n",
    "eng_stopwords.union(addToSW)\n",
    "lemma = WordNetLemmatizer()\n",
    "cv= TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ede63fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_map = {\n",
    "        'CC':None, # coordin. conjunction (and, but, or)  \n",
    "        'CD':wn.NOUN, # cardinal number (one, two)             \n",
    "        'DT':None, # determiner (a, the)                    \n",
    "        'EX':wn.ADV, # existential ‘there’ (there)           \n",
    "        'FW':None, # foreign word (mea culpa)             \n",
    "        'IN':wn.ADV, # preposition/sub-conj (of, in, by)   \n",
    "        'JJ':wn.ADJ, # adjective (yellow)                  \n",
    "        'JJR':wn.ADJ,  # adj., comparative (bigger)          \n",
    "        'JJS':wn.ADJ,  # adj., superlative (wildest)           \n",
    "        'LS':None, # list item marker (1, 2, One)          \n",
    "        'MD':None, # modal (can, should)                    \n",
    "        'NN':wn.NOUN, # noun, sing. or mass (llama)          \n",
    "        'NNS':wn.NOUN, # noun, plural (llamas)                  \n",
    "        'NNP':wn.NOUN, # proper noun, sing. (IBM)              \n",
    "        'NNPS':wn.NOUN, # proper noun, plural (Carolinas)\n",
    "        'PDT':wn.ADJ, # predeterminer (all, both)            \n",
    "        'POS':None, # possessive ending (’s )               \n",
    "        'PRP':None, # personal pronoun (I, you, he)     \n",
    "        'PRP$':None, # possessive pronoun (your, one’s)    \n",
    "        'RB':wn.ADV, # adverb (quickly, never)            \n",
    "        'RBR':wn.ADV, # adverb, comparative (faster)        \n",
    "        'RBS':wn.ADV, # adverb, superlative (fastest)     \n",
    "        'RP':[wn.ADJ, wn.ADJ_SAT], # particle (up, off)\n",
    "        'SYM':None, # symbol (+,%, &)\n",
    "        'TO':None, # “to” (to)\n",
    "        'UH':None, # interjection (ah, oops)\n",
    "        'VB':wn.VERB, # verb base form (eat)\n",
    "        'VBD':wn.VERB, # verb past tense (ate)\n",
    "        'VBG':wn.VERB, # verb gerund (eating)\n",
    "        'VBN':wn.VERB, # verb past participle (eaten)\n",
    "        'VBP':wn.VERB, # verb non-3sg pres (eat)\n",
    "        'VBZ':wn.VERB, # verb 3sg pres (eats)\n",
    "        'WDT':None, # wh-determiner (which, that)\n",
    "        'WP':None, # wh-pronoun (what, who)\n",
    "        'WP$':None, # possessive (wh- whose)\n",
    "        'WRB':None, # wh-adverb (how, where)\n",
    "        '$':None, #  dollar sign ($)\n",
    "        '#':None, # pound sign (#)\n",
    "        '“':None, # left quote (‘ or “)\n",
    "        '”':None, # right quote (’ or ”)\n",
    "        '(':None, # left parenthesis ([, (, {, <)\n",
    "        ')':None, # right parenthesis (], ), }, >)\n",
    "        ',':None, # comma (,)\n",
    "        '.':None, # sentence-final punc (. ! ?)\n",
    "        ':':None # mid-sentence punc (: ; ... – -)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b87b451d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###################### Helper Functions ######################\n",
    "\n",
    "def labelPreprocess(txt):\n",
    "    if txt == \"FAKE\":\n",
    "        return 0;\n",
    "    return 1\n",
    "\n",
    "def tokenTagingPreprocess(row):\n",
    "    rtRow = []\n",
    "    for token in row:\n",
    "        if token.casefold() not in eng_stopwords:\n",
    "            rtRow.append(token.casefold())\n",
    "    return pos_tag(rtRow);\n",
    "\n",
    "def lemmaPreprocess(row):\n",
    "    rtRow = []\n",
    "    for tag in row:\n",
    "        try:\n",
    "            rtRow.append(lemma.lemmatize(tag[0], pos=tag_map[tag[1]]));\n",
    "        except:\n",
    "            \"err\";\n",
    "    return rtRow;\n",
    "\n",
    "def fittingDT(row):\n",
    "    Rstr = ' '.join(row)\n",
    "    cv.fit_transform([Rstr])\n",
    "    \n",
    "def makeSTR(row):\n",
    "    return ' '.join(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c87e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prerocess(X, Y, is_test):\n",
    "    # container Dataframe\n",
    "    df = pd.DataFrame(columns=['title', 'text', 'label'])\n",
    "    \n",
    "    # y-test\n",
    "    df['label'] = Y.apply(labelPreprocess)\n",
    "    \n",
    "    # x-test\n",
    "    # 1- Tokenization:\n",
    "    df['title'] = [word_tokenize(row) for row in X['title']]\n",
    "    df['text'] = [word_tokenize(row) for row in X['text']]\n",
    "    \n",
    "    # 2- Get Pos-Tags:\n",
    "    df['title'] = df['title'].apply(tokenTagingPreprocess)\n",
    "    df['text'] = df['text'].apply(tokenTagingPreprocess)\n",
    "    \n",
    "    # 3- Lemmatiziation:\n",
    "    df['titleWork'] = df['title'].apply(lemmaPreprocess)\n",
    "    df['textWork'] = df['text'].apply(lemmaPreprocess)\n",
    "    \n",
    "    # 4- Remove Empty-Rows (that only contains Stop Words):\n",
    "    df.drop(axis=1,columns=['title','text'],inplace=True)\n",
    "    df = df.loc(len(df['titleWork']) > 0 & len(df['textWork']) > 0).obj\n",
    "    \n",
    "    # 5- Rows Data type array -> string\n",
    "    df['title'] = df['titleWork'].apply(makeSTR)\n",
    "    df['text'] = df['textWork'].apply(makeSTR)\n",
    "    \n",
    "    # 6- Generate TF-IDF\n",
    "    if is_test == False:\n",
    "        textBOW = cv.fit_transform(df['text'].array)\n",
    "        titleBOW = cv.fit_transform(df['title'].array)\n",
    "    else:\n",
    "        textBOW = cv.transform(df['text'].array)\n",
    "        titleBOW = cv.transform(df['title'].array)\n",
    "    \n",
    "    return [titleBOW, textBOW, df['label'].array];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abf33fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TrainReadyData = Prerocess(X_train, Y_train, False)\n",
    "trainTitle, trainText, trainLabel = TrainReadyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cef98136",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestReadyData = Prerocess(X_test, Y_test, True)\n",
    "testTitle, testText, testLabel = TestReadyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a85267d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PassiveAggressiveClassifier(max_iter=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PassiveAggressiveClassifier</label><div class=\"sk-toggleable__content\"><pre>PassiveAggressiveClassifier(max_iter=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PassiveAggressiveClassifier(max_iter=200)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modeling with title\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "clf = PassiveAggressiveClassifier(max_iter=200)\n",
    "clf.fit(trainText, trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "88b9264e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13160\\1208725304.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestText\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestLabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = clf.predict(testText.)\n",
    "acc = accuracy_score(testLabel, y_pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5205c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTheTruth(title):\n",
    "    tokens = word_tokenize(title)\n",
    "    tags = tokenTagingPreprocess(tokens)\n",
    "    lemmas = lemmaPreprocess(tags)\n",
    "    corpus = [makeSTR(lemmas)]\n",
    "    TfId = cv.transform(corpus)\n",
    "    if clf.predict(TfId) == 1:\n",
    "        return \"Real\"\n",
    "    return \"Fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb05f2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"It is: \", getTheTruth('8476,You Can Smell Hell'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4126f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
