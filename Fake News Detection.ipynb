{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e9ec9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1741    Each week, In Theory takes on a big idea in th...\n",
       "6103    Washington (CNN) A House panel approved a meas...\n",
       "1166    President Barack Obama will play host to Germa...\n",
       "329     U.S. Republican presidential candidate Donald ...\n",
       "4345    One Baltimore police officer was charged Frida...\n",
       "                              ...                        \n",
       "2655    But by amplifying his charge that President Ba...\n",
       "3751    Senate Minority Leader Harry Reid alleges that...\n",
       "6279    The reclusive leader of the Taliban hasn't bee...\n",
       "2408    Jesse Matthew Jr. has been charged with first-...\n",
       "6173    Enter your email address below to receive upda...\n",
       "Name: text, Length: 5068, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"news.csv\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df[['title', 'text']], df['label'], test_size=0.2)\n",
    "X_train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198e49d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "addToSW = set(['\\'',':',';','\\''])\n",
    "eng_stopwords.union(addToSW)\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ede63fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_map = {\n",
    "        'CC':None, # coordin. conjunction (and, but, or)  \n",
    "        'CD':wn.NOUN, # cardinal number (one, two)             \n",
    "        'DT':None, # determiner (a, the)                    \n",
    "        'EX':wn.ADV, # existential ‘there’ (there)           \n",
    "        'FW':None, # foreign word (mea culpa)             \n",
    "        'IN':wn.ADV, # preposition/sub-conj (of, in, by)   \n",
    "        'JJ':wn.ADJ, # adjective (yellow)                  \n",
    "        'JJR':wn.ADJ,  # adj., comparative (bigger)          \n",
    "        'JJS':wn.ADJ,  # adj., superlative (wildest)           \n",
    "        'LS':None, # list item marker (1, 2, One)          \n",
    "        'MD':None, # modal (can, should)                    \n",
    "        'NN':wn.NOUN, # noun, sing. or mass (llama)          \n",
    "        'NNS':wn.NOUN, # noun, plural (llamas)                  \n",
    "        'NNP':wn.NOUN, # proper noun, sing. (IBM)              \n",
    "        'NNPS':wn.NOUN, # proper noun, plural (Carolinas)\n",
    "        'PDT':wn.ADJ, # predeterminer (all, both)            \n",
    "        'POS':None, # possessive ending (’s )               \n",
    "        'PRP':None, # personal pronoun (I, you, he)     \n",
    "        'PRP$':None, # possessive pronoun (your, one’s)    \n",
    "        'RB':wn.ADV, # adverb (quickly, never)            \n",
    "        'RBR':wn.ADV, # adverb, comparative (faster)        \n",
    "        'RBS':wn.ADV, # adverb, superlative (fastest)     \n",
    "        'RP':[wn.ADJ, wn.ADJ_SAT], # particle (up, off)\n",
    "        'SYM':None, # symbol (+,%, &)\n",
    "        'TO':None, # “to” (to)\n",
    "        'UH':None, # interjection (ah, oops)\n",
    "        'VB':wn.VERB, # verb base form (eat)\n",
    "        'VBD':wn.VERB, # verb past tense (ate)\n",
    "        'VBG':wn.VERB, # verb gerund (eating)\n",
    "        'VBN':wn.VERB, # verb past participle (eaten)\n",
    "        'VBP':wn.VERB, # verb non-3sg pres (eat)\n",
    "        'VBZ':wn.VERB, # verb 3sg pres (eats)\n",
    "        'WDT':None, # wh-determiner (which, that)\n",
    "        'WP':None, # wh-pronoun (what, who)\n",
    "        'WP$':None, # possessive (wh- whose)\n",
    "        'WRB':None, # wh-adverb (how, where)\n",
    "        '$':None, #  dollar sign ($)\n",
    "        '#':None, # pound sign (#)\n",
    "        '“':None, # left quote (‘ or “)\n",
    "        '”':None, # right quote (’ or ”)\n",
    "        '(':None, # left parenthesis ([, (, {, <)\n",
    "        ')':None, # right parenthesis (], ), }, >)\n",
    "        ',':None, # comma (,)\n",
    "        '.':None, # sentence-final punc (. ! ?)\n",
    "        ':':None # mid-sentence punc (: ; ... – -)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b87b451d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###################### Helper Functions ######################\n",
    "\n",
    "def labelPreprocess(txt):\n",
    "    if txt == \"FAKE\":\n",
    "        return 0;\n",
    "    return 1\n",
    "\n",
    "def tokenTagingPreprocess(row):\n",
    "    rtRow = []\n",
    "    for token in row:\n",
    "        if token.casefold() not in eng_stopwords:\n",
    "            rtRow.append(token.casefold())\n",
    "    return pos_tag(rtRow);\n",
    "\n",
    "def lemmaPreprocess(row):\n",
    "    rtRow = []\n",
    "    for tag in row:\n",
    "        try:\n",
    "            rtRow.append(lemma.lemmatize(tag[0], pos=tag_map[tag[1]]));\n",
    "        except:\n",
    "            \"err\";\n",
    "    return rtRow;\n",
    "\n",
    "def fittingDT(row):\n",
    "    Rstr = ' '.join(row)\n",
    "    cv.fit_transform([Rstr])\n",
    "    \n",
    "def makeSTR(row):\n",
    "    return ' '.join(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c87e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv= TfidfVectorizer()\n",
    "def Prerocess(X, Y, is_test):\n",
    "    # container Dataframe\n",
    "    df = pd.DataFrame(columns=['title', 'text', 'label'])\n",
    "    \n",
    "    # y-test\n",
    "    df['label'] = Y.apply(labelPreprocess)\n",
    "    \n",
    "    # x-test\n",
    "    # 1- Tokenization:\n",
    "    df['title'] = [word_tokenize(row) for row in X['title']]\n",
    "    df['text'] = [word_tokenize(row) for row in X['text']]\n",
    "    \n",
    "    # 2- Get Pos-Tags:\n",
    "    df['title'] = df['title'].apply(tokenTagingPreprocess)\n",
    "    df['text'] = df['text'].apply(tokenTagingPreprocess)\n",
    "    \n",
    "    # 3- Lemmatiziation:\n",
    "    df['titleWork'] = df['title'].apply(lemmaPreprocess)\n",
    "    df['textWork'] = df['text'].apply(lemmaPreprocess)\n",
    "    \n",
    "    # 4- Remove Empty-Rows (that only contains Stop Words):\n",
    "    df.drop(axis=1,columns=['title','text'],inplace=True)\n",
    "    df = df.loc(len(df['titleWork']) > 0 & len(df['textWork']) > 0).obj\n",
    "    \n",
    "    # 5- Rows Data type array -> string\n",
    "    df['title'] = df['titleWork'].apply(makeSTR)\n",
    "    df['text'] = df['textWork'].apply(makeSTR)\n",
    "    \n",
    "    # 6- Generate TF-IDF\n",
    "    if is_test == False:\n",
    "        titleBOW = cv.fit_transform(df['title'].array)\n",
    "        textBOW = cv.fit_transform(df['text'].array)\n",
    "    else:\n",
    "        titleBOW = cv.transform(df['title'].array)\n",
    "        textBOW = cv.transform(df['text'].array)\n",
    "    \n",
    "    return [titleBOW, textBOW, df['label'].array];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abf33fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<5068x7301 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 36832 stored elements in Compressed Sparse Row format>,\n",
       " <5068x54451 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 1333930 stored elements in Compressed Sparse Row format>,\n",
       " <PandasArray>\n",
       " [1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "  ...\n",
       "  0, 1, 0, 0, 0, 1, 0, 1, 1, 0]\n",
       " Length: 5068, dtype: int64]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainReadyData = Prerocess(X_train, Y_train, False)\n",
    "trainTitle, trainText, trainLabel = TrainReadyData\n",
    "TrainReadyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cef98136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<1267x54451 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 9160 stored elements in Compressed Sparse Row format>,\n",
       " <1267x54451 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 320318 stored elements in Compressed Sparse Row format>,\n",
       " <PandasArray>\n",
       " [0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "  ...\n",
       "  1, 0, 0, 1, 0, 0, 1, 1, 0, 1]\n",
       " Length: 1267, dtype: int64]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestReadyData = Prerocess(X_test, Y_test, True)\n",
    "testTitle, testText, testLabel = TestReadyData\n",
    "TestReadyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a85267d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PassiveAggressiveClassifier(max_iter=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PassiveAggressiveClassifier</label><div class=\"sk-toggleable__content\"><pre>PassiveAggressiveClassifier(max_iter=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PassiveAggressiveClassifier(max_iter=100)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modeling with title\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "clf = PassiveAggressiveClassifier(max_iter=100)\n",
    "clf.fit(trainText, trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88b9264e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9313338595106551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = clf.predict(testText)\n",
    "acc = accuracy_score(testLabel, y_pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f5205c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTheTruth(title):\n",
    "    tokens = word_tokenize(title)\n",
    "    tags = tokenTagingPreprocess(tokens)\n",
    "    lemmas = lemmaPreprocess(tags)\n",
    "    corpus = [makeSTR(lemmas)]\n",
    "    TfId = cv.transform(corpus)\n",
    "    if clf.predict(TfId) == 1:\n",
    "        return \"Real\"\n",
    "    return \"Fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dec913fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is:  Fake\n"
     ]
    }
   ],
   "source": [
    "print(\"It is: \", getTheTruth('10294,Watch The Exact Moment Paul Ryan Committed Political Suicide At A Trump'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
